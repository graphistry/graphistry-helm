
#ingress management - determines if ingress is going to be on internal load balancer 
ingress:
  management:
    annotations:
      #service.beta.kubernetes.io/azure-load-balancer-internal: "true"
      #cloud.google.com/load-balancer-type: "Internal"
      #service.beta.kubernetes.io/aws-load-balancer-internal: "true"



#the namespace of the ingress controller - this is the namespace that the ingress controller is going to be deployed to.
ingressNamespace: ingress-nginx


#max surge of pods in rolling updates
maxSurge : "10%"



#forwards backend proxy's headers to ingress controller
fwdHeaders: false

httpTesting: false

#set to development in dev mode
nodeEnv: production

#set to developmet in dev mode
appEnvironment: production

#set to config.settings.dev in dev mode
djangoSettingsModule: "config.settings.production"

graphistryCPUMode: "0"

#set to true in dev mode
djangoDebug: "False"

nginxPorts:
  #port for nginx service to listen on
  portOne: 80
  portTwo: 443

metrics: false

#ports for nexus service to listen on
nexusPort: 
  portOne: 8000
  portTwo: 8080

# graph app kit public - determines if public dashboard is going to be deployed
graphAppKitPublic: true

# graph app kit private - determines if private dashboard is going to be deployed
graphAppKitPrivate: true



# rolling update deployment strategy switch (postgres and nexus are exempt)
rollingUpdate: false

# django session cookie timeout (seconds)
sessionCookieAge : "1209600"

# django drf-jwt, jwt token timeout (seconds)
jwtExpirationDelta : "3600"

# ENABLE django silk - performance analysis library
enableDjangoSilk : "False"


#domain - set to  the node external ip
#example: 18.116.94.149.nip.io - graphistry.18.116.94.149.nip.io
domain: 

#set tlsStaging to true to enable tls staging
tlsStaging: false

#set tls to true to enable tls in production
tls: false

#email to send tls notifications to
tlsEmail: ""

#enables longhorn dashboard
longhornDashboard: false



#cuda version
cuda:
  version: "11.4"


#caddy repository name
caddy:
  repository: caddy

#graph app kit repository name and tag
graphAppKit:
  repository: graph-app-kit-st


#redis repository name and tag
redis:
  repository: redis
  tag: 6.2.7



#streamgl-viz repository name 
streamglviz:
  repository: streamgl-viz

#streamgl-viz repository name 
streamglvizDev:
  repository: graphistry-viz-dev

#nginx repository name 
nginx:
  repository: streamgl-nginx

#nginx repository name 
nginxDev:
  repository: graphistry-nginx-dev

#streamgl-vgraph-etl repository name 
streamglvgraph:
  repository: streamgl-vgraph-etl


#streamgl-gpu repository name 
streamglgpu:
  repository: streamgl-gpu


#streamgl-sessions repository name
streamglsessions:
  repository: streamgl-sessions


#graphistry pivot repository name 
pivot:
  repository: graphistry-pivot

#graphistry pivot dev repository
pivotDev:
  repository: graphistry-pivot-dev


#jupyter notebook repository name 
notebook:
  repository: jupyter-notebook


#graphistry nexus repository name 
nexus:
  repository: graphistry-nexus


#graphistry nexus repository name 
nexusDev:
  repository: graphistry-nexus-dev

#forge-etl-python repository name 
forgeetlpython:
  repository: etl-server-python

#forge-etl-python dev repository name
forgeetlpythonDev:
  repository: graphistry-forge-python-dev

#forge-etl repository name 
forgeetl:
  repository: etl-server
#sets the number of dask cuda workers
dask:
  workers: 1

#dask-scheduler repository name 
daskscheduler:
  repository: etl-server-python


#dask-cuda-worker repository name 
daskcudaworker:
  repository: etl-server-python

#gak username to be set to a user registered in graphistry
graphAppKitusername: 

#gak username password to be set to a user registered in graphistry
graphAppKitpassword: 

## graphistry key for dev mode in pivot deployment
graphistryKey:



#environment variables 
 # can be set like helm install chart_name --name release_name \
 #--set env.DBUser="FOO" --set env.DBPassword="BAR"
env:
 - name: HOST
   value: 0.0.0.0
 - name: AUTH_LDAP_BIND_PASSWORD
   value: abc123xyz
 - name: DJANGO_SECRET_KEY
   value: abc123xyz
 - name: LEGACY_API_KEY_CANARY
   value: abc123xyz
 - name: LEGACY_API_KEY_SECRET
   value: abc123xyz
 - name: DASK_DISTRIBUTED__WORKER__DAEMON
   value: "False"
 - name: CHUNK_DASK_CUDF_ROWS
   value: "500000"
 - name: DASK_CSV_BLOCKSIZE
   value: 64 MiB
 - name: DASK_CUDF_CSV_CHUNKSIZE
   value: 64 MiB
 - name: FORGE_NUM_WORKERS
   value: "4"
 - name: REMOTE_DASK
   value: dask-scheduler:8786
 - name: REMOTE_DASK_DIAGNOSTICS
   value: dask-scheduler:8787
 - name: AIR_GAPPED
   value: "0"
 - name: PIVOT_PORT 
   value: "8080"
 - name: PORT
   value: "8080"
 - name: NODE_NO_WARNINGS
   value: "1"
 - name: USE_LOCAL_USER
   value: "false"
 - name: NODE_OPTIONS
   value: --max-old-space-size=64000 --stack-trace-limit=20
 - name: NODE_REDIS_URL
   value: redis://redis:6379
 - name: NODE_TLS_REJECT_UNAUTHORIZED
   value: "0"
 - name: CELERY_FLOWER_PASSWORD
   value: JPkK3b2ihuwAGLJ8AjE3aNRmEEvYm5jyCTVlqDbRzzOAMrZhyzJ3SfgnQZMrBBCw
 - name: CELERY_FLOWER_USER
   value: ATZpVOzzQgESuKVmUYQDoJwNqjvueLoP
 - name: DJANGO_ADMIN_URL
   value: admin/
 - name: DJANGO_ALLOWED_HOSTS
   value: '*'
 - name: DJANGO_SECURE_SSL_REDIRECT
   value: "False"
 - name: GOOGLE_ANALYTICS_ID
   value: UA-59712214-2
 - name: IS_SIGNUPS_OPEN_AFTER_FIRST_DEFAULT
   value: "false"
 - name: IS_SOCIAL_AUTH_GITHUB_OPEN_DEFAULT
   value: "false"
 - name: IS_SOCIAL_AUTH_GOOGLE_OPEN_DEFAULT
   value: "false"
 - name: JWT_AUTH_COOKIE
   value: graphistry_jwt
 - name: REDIS_URL
   value: redis://redis:6379/0
 - name: USE_DOCKER
   value: "yes"
 - name: PIVOT_CONFIG_FILES
   value: /opt/graphistry/apps/core/pivot/data/config/config.json
 - name: CLEAR_LOCAL_DATASET_CACHE_ON_STARTUP
   value: "false"
 - name: CLEAR_LOCAL_SESSION_CACHE_ON_STARTUP
   value: "true"
 - name: FORGE_ETL_HOSTNAME
   value: nginx
 - name: FORGE_ETL_PATH
   value: /api/v1/etl/
 - name: FORGE_ETL_PORT
   value: "80"
 - name: GRAPH_PLAY_TIMEOUTMS
   value: "60000"
 - name: LOCAL_DATASET_CACHE
   value: "true"
 - name: LOCAL_DATASET_CACHE_DIR
   value: /opt/graphistry/data
 - name: LOCAL_SESSIONS_CACHE_DIR
   value: /opt/graphistry/data
 - name: LOCAL_WORKBOOK_CACHE
   value: "true"
 - name: LOCAL_WORKBOOK_CACHE_DIR
   value: /opt/graphistry/data
 - name: NGINX_HOST
   value: nginx
 - name: PM2_MAX_WORKERS
   value: "4"
 - name: STREAMGL_CPU_NUM_WORKERS
   value: "4"
 - name: STREAMGL_INACTIVITY_TIMEOUT_MS
   value: "30000"
 - name: STREAMGL_NUM_WORKERS
   value: "4"
 - name: UPLOAD_MAX_SIZE
   value: 1G
 - name: ZIPKIN_ENABLED
   value: "false"
 - name: ACME_AGREE
   value: "true"
 - name: ENABLE_TELEMETRY
   value: "false"

#streamlit environment variables
 # can be set like helm upgrade -i  chart_name --name release_name \
 #--set stENVPublic.LOG_LEVEL="FOO" 
stENVPublic:
 - name: LOG_LEVEL
   value: DEBUG
 - name: BASE_PATH
   value: 
 - name: BASE_URL
   value: "http://localhost:8501"
 - name: ST_PUBLIC_PORT
   value: 8501
 - name: GRAPH_VIEWS
   value: "/apps/views"
 - name: COMPOSE_PROJECT_NAME
   value: 
 - name: VERSION_BASE
   value: "v2.32.4"
 - name: NEPTUNE_READER_PROTOCOL
   value: 
 - name: NEPTUNE_READER_HOST
   value: 
 - name: NEPTUNE_READER_PORT
   value: 
 - name: NEPTUNE_KEY_PATH
   value: 
 - name: NEPTUNE_TUNNEL_HOST
   value: 
 - name: NEPTUNE_TUNNEL_USER
   value:  
 - name: TIGERGRAPH_HOST
   value: 
 - name: TIGERGRAPH_USERNAME
   value: 
 - name: TIGERGRAPH_PASSWORD
   value: 
 - name: TIGERGRAPH_GRAPHNAME
   value: 
 - name: TIGERGRAPH_SECRET
   value: 

#streamlit environment variables
 # can be set like helm upgrade -i  chart_name --name release_name \
 #--set stENVPrivate.LOG_LEVEL="FOO" 
stENVPrivate:
 - name: LOG_LEVEL
   value: DEBUG
 - name: BASE_PATH
   value: 
 - name: BASE_URL
   value: "http://localhost:8502"
 - name: ST_PUBLIC_PORT
   value: 8502
 - name: GRAPH_VIEWS
   value: "/apps/views"
 - name: COMPOSE_PROJECT_NAME
   value: 
 - name: VERSION_BASE
   value: "v2.32.4"
 - name: NEPTUNE_READER_PROTOCOL
   value: 
 - name: NEPTUNE_READER_HOST
   value: 
 - name: NEPTUNE_READER_PORT
   value: 
 - name: NEPTUNE_KEY_PATH
   value: 
 - name: NEPTUNE_TUNNEL_HOST
   value: 
 - name: NEPTUNE_TUNNEL_USER
   value:  
 - name: TIGERGRAPH_HOST
   value: 
 - name: TIGERGRAPH_USERNAME
   value: 
 - name: TIGERGRAPH_PASSWORD
   value: 
 - name: TIGERGRAPH_GRAPHNAME
   value: 
 - name: TIGERGRAPH_SECRET
   value: 


global:
  #storage class provisioner - Each StorageClass has a provisioner that determines what volume plugin is used for provisioning PVs.
  provisioner: kubernetes.io/aws-ebs
# multinode selector switch to determine if going multi/single node
  multiNode: false
  #container registry name
  containerregistry:
    name: acrgraphistryk8s.azurecr.io
  #dev mode for debugging with nexus, postgres and nginx
  devMode: false
  #graphitry tag for the docker image
  graphistry: graphistry
  postgres:
  #postgres repository name   
    repository: graphistry-postgres
    #db name
    name: graphistry
    #db user
    user: graphistry
  #port for postgres service to listen on
    port: 5432
  #hostname for postgres
    host: postgres
  #tag for the docker image
  tag: latest
  #image pull policy
  imagePullPolicy: IfNotPresent #could also be Always
  #restart policy
  restartPolicy: Always
  #image pull secrets name
  imagePullSecrets: acr-secret
#node selector to determine which node to deploy cluster to
  nodeSelector: 
  #{"accelerator": "nvidia"}
  #--set nodeSelector."accelerator"=nvidia
  #{"kubernetes.io/hostname": "ip-172-31-32-176.us-east-2.compute.internal"}
  #--set nodeSelector."kubernetes\\.io/hostname"=ip-172-31-7-234.us-east-2.compute.internal
  logs:
    LogLevel: INFO
    GraphistryLogLevel: INFO
